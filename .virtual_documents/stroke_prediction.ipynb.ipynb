import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt


df = pd.read_csv(r")


df.head(5)





df.isnull().sum()


df.dtypes


df['bmi'].fillna(int(df['bmi'].mean()),inplace = True)
df.isnull().sum()


df2 = df.drop('id',axis=1)
df2.head()





categorical_cols = ['gender','ever_married','work_type','Residence_type','smoking_status']


from sklearn.preprocessing import OrdinalEncoder


oe = OrdinalEncoder()
df2[categorical_cols] = oe.fit_transform(df2[categorical_cols])


df2


df2[categorical_cols] = df2[categorical_cols].astype(int)


df2.dtypes


df2['stroke'].value_counts()


from sklearn.utils import resample


df_major = df2[(df2['stroke']==0)]
df_minor = df2[(df2['stroke']==1)]
df_minor_resmapled = resample(df_minor,replace=True,n_samples=4861,random_state=42)
df_resampled = pd.concat([df_minor_resmapled,df_major])


import seaborn as sns
import matplotlib.pyplot as plt

sns.countplot(x='stroke', data=df_resampled)
plt.title('Distribution of Stroke Cases')
plt.xlabel('Stroke (0 = No, 1 = Yes)')
plt.ylabel('Count')
plt.show()


sns.heatmap(df_resampled.corr(), fmt='.2g')



x = df_resampled.iloc[:,:-1]
y = df_resampled['stroke']


from sklearn.model_selection import train_test_split,cross_val_score,cross_val_predict
from sklearn.metrics import accuracy_score
x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=7)





from sklearn.tree import DecisionTreeClassifier
dtc = DecisionTreeClassifier()
dtc.fit(x_train,y_train)


print("Accuracy Score :",round(dtc.score(x_test,y_test)*100,2),"%")





from xgboost import XGBClassifier
xgb = XGBClassifier()
xgb.fit(x_train,y_train)


print("Accuracy Score :",round(xgb.score(x_test,y_test)*100,2),"%")





from sklearn.ensemble import RandomForestClassifier
rfc = RandomForestClassifier()
rfc.fit(x_train,y_train)


print("Accuracy Score :",round(rfc.score(x_test,y_test)*100,2),"%")





from sklearn.linear_model import LogisticRegression
lr = LogisticRegression()
lr.fit(x_train,y_train)


print("Accuracy Score :",round(lr.score(x_test,y_test)*100,2),"%")


#importing classification report and confusion Matrix
from sklearn.metrics import classification_report, confusion_matrix





y_pred = xgb.predict(x_test)
print("Classification Report", classification_report(y_test,y_pred))


cm = confusion_matrix(y_test,y_pred)
plt.figure(figsize=(5,5))
sns.heatmap(data=cm,linewidths=.5,annot=True,square=True,cmap='Blues')
plt.xlabel("Predicted label")
plt.ylabel("Actual label")
sample_title = 'Accuracy Score: {0}'.format(xgb.score(x_test,y_test))
plt.title(sample_title,size=15)


model = XGBClassifier(eval_metric=['error','logloss'])
eval_set = [(x_train,y_train),(x_test,y_test)]
model.fit(x_train,y_train,eval_set=eval_set,verbose=True)
results = model.evals_result()
epochs = len(results['validation_0']['error'])
x_axis = range(0,epochs)
# plot Log Loss
fig,ax = plt.subplots()
ax.plot(x_axis,results['validation_0']['logloss'],label = 'Train')
ax.plot(x_axis,results['validation_1']['logloss'],label = 'Test')
ax.legend()
plt.ylabel('Log Loss')
plt.show()



model = XGBClassifier(eval_metric="logloss",early_stopping_rounds=10)
eval_set = [(x_test, y_test)]
model.fit(x_train,y_train, eval_set=eval_set, verbose=True)
     


from xgboost import plot_importance


plot_importance(model,importance_type='cover')
plt.title("Feature importance by cover")
plt.show()





y_pred = lr.predict(x_test)
print("Classification report - \n",classification_report(y_test,y_pred))


cm = confusion_matrix(y_test,y_pred)
plt.figure(figsize=(5,5))
sns.heatmap(data=cm,linewidths=5, annot=True,square=True,cmap='Blues')
plt.xlabel("Predicted label")
plt.ylabel("Actual label")
all_sample_title = 'Accuracy Score: {0}'.format(lr.score(x_test,y_test)*100)
plt.title(all_sample_title,size = 15)


from sklearn.metrics import roc_curve,roc_auc_score
y_pred_proba = lr.predict_proba(x_test)[:][:,1]
df_actual_predicted  = pd.concat([pd.DataFrame(np.array(y_test),columns=["y_actual"]),pd.DataFrame(y_pred_proba,columns=['y_pred_proba'])],axis=1)
df_actual_predicted.index = y_test.index
fpr,tpr,tr = roc_curve(df_actual_predicted['y_actual'],df_actual_predicted['y_pred_proba'])
auc = roc_auc_score(df_actual_predicted['y_actual'],df_actual_predicted['y_pred_proba'])
plt.plot(fpr,tpr,label='AUC = %0.4f' % float(auc))
plt.plot(fpr,fpr,linestyle='--',color='k')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title("ROC Curve",size=15)
plt.legend()


y_pred_prob = lr.predict_proba(x_test)[0:10]
y_pred_prob_df = pd.DataFrame(data = y_pred_prob*100,columns=['Prob. of dont have Stroke','Prob. of having Stroke']).round(2)
y_pred_prob_df


y_pred1 = lr.predict_proba(x_test)[:,1]
sns.kdeplot(y_pred1, shade=True, color="purple")
plt.title('KDE Plot of Predicted Stroke Probabilities')
plt.xlabel('Predicted Probability of Stroke')
plt.ylabel('Density')
plt.xlim(0, 1)
plt.grid(True)
plt.show()






Xnew = [[1, 50, 0, 1, 0, 3, 1, 140, 25, 2]]
y_pred_prob2 = lr.predict_proba(Xnew)
y_pred_prob_df2 = pd.DataFrame(data=y_pred_prob2, columns=['Prob of dont have stroke', 'Prob of have stroke'])
y_pred_prob_df2





y_pred = rfc.predict(x_test)
print('Classification Report- \n',classification_report(y_test,y_pred))


cm = confusion_matrix(y_test,y_pred)
sns.heatmap(data=cm,linewidths=5,annot=True,square=True,cmap='Blues')
plt.xlabel('Predicted label')
plt.ylabel('Actual label')
all_sample_title = 'Accuracy Score {0}'.format(rfc.score(x_test,y_test)*100)
plt.title(all_sample_title,size=15)                           


# already imported roc_curve,roc_auc_score
y_pred_prob = rfc.predict_proba(x_test)[:][:,1]
df_actual_predicted = pd.concat([pd.DataFrame(np.array(y_test),columns=["y_actual"]),pd.DataFrame(np.array(y_pred_prob),columns=['y_pred_prob'])],axis=1)
df_actual_predicted.index = y_test.index
fpr,tpr,tr = roc_curve(df_actual_predicted['y_actual'],df_actual_predicted['y_pred_prob'])
auc = roc_auc_score(df_actual_predicted['y_actual'],df_actual_predicted['y_pred_prob'])
plt.plot(fpr,tpr, label='AUC %0.4f' %auc)
plt.plot(fpr,fpr,linestyle='--',color='k')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title("ROC Curve",size=15)
plt.legend()


# Feature Importance
imp_df = pd.DataFrame({
    'Feature Name': x_train.columns,
    'Importance': rfc.feature_importances_
})
imp_df.sort_values(by='Importance',ascending=False)


y_pred_prob = rfc.predict_proba(x_test)[0:10]
y_pred_prob_df = pd.DataFrame(data=y_pred_prob*100, columns=['Prob of dont have stroke', 'Prob of have stroke']).round(2)
y_pred_prob_df


y_pred2 = rfc.predict_proba(x_test)[:,1]
sns.kdeplot(y_pred1, shade=True, color="purple")
plt.title('KDE Plot of Predicted Stroke Probabilities')
plt.xlabel('Predicted Probability of Stroke')
plt.ylabel('Density')
plt.xlim(0, 1)
plt.grid(True)
plt.show()






Xnew2 = [[29,48,69,23,4,8,2,7,106,45]]
y_pred_prob3 = rfc.predict_proba(Xnew2)
y_pred_prob3_df = pd.DataFrame(data=y_pred_prob3*100,columns=['Prob. of dont have Stroke','Prob of have Stroke'])
y_pred_prob3_df





from sklearn.model_selection import GridSearchCV

param_grid = {
    'n_estimators': [100, 200],
    'max_depth': [None, 10, 20],
    'min_samples_split': [2, 5],
}

grid = GridSearchCV(RandomForestClassifier(), param_grid, cv=5, scoring='accuracy')
grid.fit(x_train, y_train)
grid.best_params_






print("Accuracy Score is: ",(grid.best_score_*100).round(2))


gender = input("Your Gender (0=Female, 1=Male) : ")
age = input("Your Age: ")
hypertension = input("Do you have hypertension ? (0 = No, 1 = Yes) : ")
heart = input("Do you have heart disease ? (0 = No, 1 = Yes) :")
marry = input("Did you ever married ? (0 = No, 1 = Yes) :")
work = input("Your Worktype ? (0 = children, 1 = Government job, 2 = Never worked, 3 = Private, 4 = Self Employed) : ")
residence = input("Your Residence type ? (0 = Rural, 1 = Urban) : ")
avg = input("Average Glucose Level : ")
bmi = input("Your BMI : ")
smoke = input("Your Smoking status ? (0 = never smoked, 1 = formerly smoked, 2 = smokes, 3 = unknown) : ")

Xnew3 = [[gender, age, hypertension, heart, marry, work, residence, avg,bmi,smoke]]


y_pred_prob4 = grid.predict_proba(Xnew3)
y_pred_prob_df4 = pd.DataFrame(data=y_pred_prob4*100, columns=['Prob of dont have stroke', 'Prob of have stroke'])
y_pred_prob_df4


import joblib

# Save it
joblib.dump(rfc, 'stroke_model.pkl')

# Later or in another file/notebook
rfc_loaded = joblib.load('stroke_model.pkl')

# Predict with the loaded model
y_pred = rfc_loaded.predict(x_test)




